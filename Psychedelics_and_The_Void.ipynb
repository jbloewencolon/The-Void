{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1GNB1vdlZQjuDHR0H0E2vlJh_vKMZhwNF",
      "authorship_tag": "ABX9TyMfARgtV7JwswfWpeMDxs5n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbloewencolon/The-Void/blob/main/Psychedelics_and_The_Void.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OywWl-ECjvZv",
        "outputId": "f282dab6-65db-49f7-d582-c917a735422f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "!pip install nltk\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk import bigrams, trigrams\n",
        "from nltk.probability import FreqDist\n",
        "from collections import Counter\n",
        "import string\n",
        "import os\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download NLTK stop words if not already downloaded\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Download NLTK data if not already downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the VADER lexicon (if not already downloaded)\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Psychedelic-Trip-Report-Generator/Data/processed.csv')\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7djW3WBj-RU",
        "outputId": "76e17fb2-ef95-4e4a-f0bb-805a30eefce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 67875 entries, 0 to 67874\n",
            "Data columns (total 10 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   Unnamed: 0        67875 non-null  int64 \n",
            " 1   drug              67875 non-null  object\n",
            " 2   dosage            66103 non-null  object\n",
            " 3   delivery          65447 non-null  object\n",
            " 4   weight            67875 non-null  int64 \n",
            " 5   gender            67875 non-null  object\n",
            " 6   report            67875 non-null  object\n",
            " 7   processed_report  67875 non-null  object\n",
            " 8   mixed             67875 non-null  int64 \n",
            " 9   drug_category     67875 non-null  object\n",
            "dtypes: int64(3), object(7)\n",
            "memory usage: 5.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_and_print_void_sentences(dataframe):\n",
        "    # Iterate through the \"report\" column\n",
        "    for index, row in dataframe.iterrows():\n",
        "        report_text = row['report']\n",
        "\n",
        "        # Split the report text into sentences using regular expressions\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', report_text)\n",
        "\n",
        "        # Check each sentence for the word \"Void\"\n",
        "        for sentence in sentences:\n",
        "            if 'Void' in sentence:\n",
        "                print(f\"Report Index: {index}, Sentence: {sentence}\\n\")\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "find_and_print_void_sentences(df)"
      ],
      "metadata": {
        "id": "ozeEnFQPkBKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment_with_void(dataframe):\n",
        "    # Initialize the Sentiment Intensity Analyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Iterate through the \"report\" column\n",
        "    for index, row in dataframe.iterrows():\n",
        "        report_text = row['processed_report']\n",
        "\n",
        "        # Split the report text into sentences using regular expressions\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', report_text)\n",
        "\n",
        "        # Check each sentence for the word \"Void\"\n",
        "        for sentence in sentences:\n",
        "            if 'Void' in sentence:\n",
        "                sentiment_scores = sia.polarity_scores(sentence)\n",
        "                print(f\"Report Index: {index}, Sentence: {sentence}\")\n",
        "                print(\"Sentiment Scores:\", sentiment_scores)\n",
        "                print(\"\\n\")\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "analyze_sentiment_with_void(df)\n"
      ],
      "metadata": {
        "id": "ONzaiNPgkVE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import re\n",
        "\n",
        "def categorize_sentiment_reports(dataframe):\n",
        "    # Initialize the Sentiment Intensity Analyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Initialize counters for each sentiment category and for mixed and not mixed reports\n",
        "    positive_count = 0\n",
        "    neutral_count = 0\n",
        "    negative_count = 0\n",
        "    mixed_positive_count = 0\n",
        "    mixed_neutral_count = 0\n",
        "    mixed_negative_count = 0\n",
        "    not_mixed_positive_count = 0\n",
        "    not_mixed_neutral_count = 0\n",
        "    not_mixed_negative_count = 0\n",
        "\n",
        "    # Iterate through the DataFrame\n",
        "    for index, row in dataframe.iterrows():\n",
        "        report_text = row['report']\n",
        "        is_mixed = row['mixed']\n",
        "\n",
        "        # Split the report text into sentences using regular expressions\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', report_text)\n",
        "\n",
        "        # Initialize sentiment category counts for the current report\n",
        "        current_positive_count = 0\n",
        "        current_neutral_count = 0\n",
        "        current_negative_count = 0\n",
        "\n",
        "        # Check each sentence for the word \"Void\" and categorize by sentiment\n",
        "        for sentence in sentences:\n",
        "            if 'Void' in sentence:\n",
        "                sentiment_scores = sia.polarity_scores(sentence)\n",
        "                compound_score = sentiment_scores['compound']\n",
        "\n",
        "                if compound_score >= 0.05:\n",
        "                    current_positive_count += 1\n",
        "                elif compound_score <= -0.05:\n",
        "                    current_negative_count += 1\n",
        "                else:\n",
        "                    current_neutral_count += 1\n",
        "\n",
        "        # Update the overall sentiment category counts\n",
        "        positive_count += current_positive_count\n",
        "        neutral_count += current_neutral_count\n",
        "        negative_count += current_negative_count\n",
        "\n",
        "        # Categorize mixed and not mixed reports\n",
        "        if is_mixed:\n",
        "            mixed_positive_count += current_positive_count\n",
        "            mixed_neutral_count += current_neutral_count\n",
        "            mixed_negative_count += current_negative_count\n",
        "        else:\n",
        "            not_mixed_positive_count += current_positive_count\n",
        "            not_mixed_neutral_count += current_neutral_count\n",
        "            not_mixed_negative_count += current_negative_count\n",
        "\n",
        "    # Print the counts for each sentiment category and mixed vs. not mixed reports\n",
        "    print(\"Positive Reports:\", positive_count)\n",
        "    print(\"Neutral Reports:\", neutral_count)\n",
        "    print(\"Negative Reports:\", negative_count)\n",
        "    print(\"Mixed Positive Reports:\", mixed_positive_count)\n",
        "    print(\"Mixed Neutral Reports:\", mixed_neutral_count)\n",
        "    print(\"Mixed Negative Reports:\", mixed_negative_count)\n",
        "    print(\"Not Mixed Positive Reports:\", not_mixed_positive_count)\n",
        "    print(\"Not Mixed Neutral Reports:\", not_mixed_neutral_count)\n",
        "    print(\"Not Mixed Negative Reports:\", not_mixed_negative_count)\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "categorize_sentiment_reports(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOoHbe6nluyP",
        "outputId": "0fb7b77c-e3cd-40a7-fb3e-e02ab79f8cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Reports: 102\n",
            "Neutral Reports: 65\n",
            "Negative Reports: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean and tokenize text, removing stop words\n",
        "def clean_and_tokenize(text):\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove words with less than 2 characters and any punctuation, numbers, or symbols\n",
        "    tokens = [word for word in tokens if len(word) >= 2 and word.isalpha()]\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "\n",
        "    return tokens\n",
        "# Function to save tokenized data to a file\n",
        "def save_tokenized_data(tokens, filename):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(tokens, file)\n",
        "\n",
        "# Function to load tokenized data from a file\n",
        "def load_tokenized_data(filename):\n",
        "    with open(filename, 'rb') as file:\n",
        "        tokens = pickle.load(file)\n",
        "    return tokens\n",
        "\n",
        "# Check if tokenized data file exists, if not, tokenize and save\n",
        "tokenized_data_filename = 'tokenized_data.pkl'\n",
        "if os.path.exists(tokenized_data_filename):\n",
        "    processed_report_tokens = load_tokenized_data(tokenized_data_filename)\n",
        "else:\n",
        "    processed_report_tokens = []\n",
        "    for index, row in df.iterrows():\n",
        "        tokens = clean_and_tokenize(row['report'])\n",
        "        processed_report_tokens.append(tokens)\n",
        "\n",
        "    # Save tokenized data to a file\n",
        "    save_tokenized_data(processed_report_tokens, tokenized_data_filename)\n"
      ],
      "metadata": {
        "id": "0KHQql-ByLiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_word_bigrams_and_trigrams(dataframe):\n",
        "    # Create empty lists to store word bigrams and trigrams\n",
        "    void_word_bigrams = []\n",
        "    void_word_trigrams = []\n",
        "\n",
        "    # Iterate through the \"processed_report\" column\n",
        "    for index, row in dataframe.iterrows():\n",
        "        processed_report_tokens = clean_and_tokenize(row['report'])\n",
        "\n",
        "        # Check if \"void\" is present in the tokens\n",
        "        if 'void' in processed_report_tokens:\n",
        "            void_index = processed_report_tokens.index('void')\n",
        "\n",
        "            # Generate word bigrams and trigrams around \"void\"\n",
        "            void_word_bigrams.extend(list(bigrams(processed_report_tokens))[max(0, void_index - 1):min(void_index + 2, len(processed_report_tokens))])\n",
        "            void_word_trigrams.extend(list(trigrams(processed_report_tokens))[max(0, void_index - 1):min(void_index + 3, len(processed_report_tokens))])\n",
        "\n",
        "    # Calculate the most common word bigrams and trigrams\n",
        "    common_void_word_bigrams = FreqDist(void_word_bigrams).most_common(50)\n",
        "    common_void_word_trigrams = FreqDist(void_word_trigrams).most_common(50)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Top 50 Word Bigrams around 'void':\")\n",
        "    for bigram, count in common_void_word_bigrams:\n",
        "        print(f\"{bigram}: {count}\")\n",
        "\n",
        "    print(\"\\nTop 50 Word Trigrams around 'void':\")\n",
        "    for trigram, count in common_void_word_trigrams:\n",
        "        print(f\"{trigram}: {count}\")\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "find_top_word_bigrams_and_trigrams(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgQJUBcqmKZ0",
        "outputId": "fd8b2b99-9d05-443c-a2da-ea6337ab9e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 50 Word Bigrams around 'void':\n",
            "('black', 'void'): 160\n",
            "('void', 'space'): 43\n",
            "('empty', 'void'): 43\n",
            "('dark', 'void'): 39\n",
            "('infinite', 'void'): 33\n",
            "('void', 'felt'): 33\n",
            "('fill', 'void'): 30\n",
            "('sort', 'void'): 30\n",
            "('floating', 'void'): 29\n",
            "('great', 'void'): 28\n",
            "('void', 'could'): 28\n",
            "('void', 'like'): 27\n",
            "('like', 'void'): 27\n",
            "('back', 'void'): 26\n",
            "('endless', 'void'): 25\n",
            "('white', 'void'): 23\n",
            "('void', 'place'): 22\n",
            "('void', 'filled'): 22\n",
            "('void', 'behind'): 21\n",
            "('vast', 'void'): 20\n",
            "('void', 'time'): 20\n",
            "('experience', 'void'): 18\n",
            "('void', 'nothingness'): 17\n",
            "('completely', 'void'): 17\n",
            "('void', 'seems'): 17\n",
            "('blackness', 'void'): 16\n",
            "('void', 'would'): 15\n",
            "('complete', 'void'): 15\n",
            "('void', 'universe'): 14\n",
            "('void', 'beyond'): 14\n",
            "('void', 'feel'): 14\n",
            "('void', 'left'): 14\n",
            "('entered', 'void'): 14\n",
            "('swirling', 'void'): 14\n",
            "('void', 'center'): 13\n",
            "('null', 'void'): 13\n",
            "('void', 'background'): 13\n",
            "('nothing', 'void'): 13\n",
            "('void', 'one'): 13\n",
            "('void', 'thought'): 13\n",
            "('void', 'friend'): 13\n",
            "('time', 'void'): 13\n",
            "('see', 'void'): 12\n",
            "('blue', 'void'): 12\n",
            "('filled', 'void'): 12\n",
            "('void', 'stretching'): 12\n",
            "('void', 'nothing'): 11\n",
            "('going', 'void'): 11\n",
            "('falling', 'void'): 11\n",
            "('space', 'time'): 11\n",
            "\n",
            "Top 50 Word Trigrams around 'void':\n",
            "('void', 'space', 'time'): 11\n",
            "('replace', 'void', 'friend'): 11\n",
            "('void', 'friend', 'left'): 11\n",
            "('friend', 'left', 'spiralled'): 11\n",
            "('left', 'spiralled', 'onto'): 11\n",
            "('aimlessly', 'void', 'confusion'): 11\n",
            "('void', 'confusion', 'progress'): 11\n",
            "('confusion', 'progress', 'took'): 11\n",
            "('progress', 'took', 'Adderall'): 11\n",
            "('sort', 'void', 'stretching'): 10\n",
            "('void', 'stretching', 'feeling'): 10\n",
            "('stretching', 'feeling', 'energy'): 10\n",
            "('feeling', 'energy', 'flowing'): 10\n",
            "('see', 'void', 'nearly'): 9\n",
            "('void', 'nearly', 'intense'): 9\n",
            "('nearly', 'intense', 'first'): 9\n",
            "('intense', 'first', 'time'): 9\n",
            "('beautiful', 'void', 'therapeutic'): 9\n",
            "('void', 'therapeutic', 'qualities'): 9\n",
            "('therapeutic', 'qualities', 'creative'): 9\n",
            "('qualities', 'creative', 'problem'): 9\n",
            "('black', 'void', 'place'): 8\n",
            "('void', 'place', 'heads'): 8\n",
            "('place', 'heads', 'numbered'): 8\n",
            "('heads', 'numbered', 'pool'): 8\n",
            "('forwards', 'void', 'feel'): 8\n",
            "('void', 'feel', 'movement'): 8\n",
            "('feel', 'movement', 'similar'): 8\n",
            "('movement', 'similar', 'feeling'): 8\n",
            "('dark', 'void', 'inner'): 8\n",
            "('void', 'inner', 'space'): 8\n",
            "('inner', 'space', 'see'): 8\n",
            "('space', 'see', 'psychedelics'): 8\n",
            "('void', 'felt', 'like'): 8\n",
            "('experience', 'void', 'sedative'): 8\n",
            "('void', 'sedative', 'medication'): 8\n",
            "('sedative', 'medication', 'although'): 8\n",
            "('medication', 'although', 'wine'): 8\n",
            "('hour', 'void', 'state'): 7\n",
            "('void', 'state', 'nothingness'): 7\n",
            "('state', 'nothingness', 'state'): 7\n",
            "('nothingness', 'state', 'high'): 7\n",
            "('black', 'void', 'could'): 7\n",
            "('black', 'void', 'behind'): 7\n",
            "('bleeding', 'void', 'fractal'): 7\n",
            "('void', 'fractal', 'complexity'): 7\n",
            "('fractal', 'complexity', 'far'): 7\n",
            "('complexity', 'far', 'approximately'): 7\n",
            "('sort', 'void', 'space'): 7\n",
            "('space', 'time', 'apartment'): 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_results_to_print = 50  # Set your desired limit\n",
        "printed_count = 0\n",
        "\n",
        "for index, report_text in matching_reports:\n",
        "    if printed_count >= max_results_to_print:\n",
        "        break\n",
        "\n",
        "    print(f\"Report Index: {index}\")\n",
        "\n",
        "    # Split the report text into sentences using regular expressions\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', report_text)\n",
        "\n",
        "    # Check each sentence for the presence of 'void' or any single keyword\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()  # Split sentence into words\n",
        "        if 'void' in words:\n",
        "            print(f\"Sentence (Contains 'void'): {sentence}\\n\")\n",
        "        else:\n",
        "            for keyword in keywords_to_search:\n",
        "                if keyword in words:\n",
        "                    print(f\"Sentence (Contains '{keyword}'): {sentence}\\n\")\n",
        "\n",
        "    printed_count += 1\n",
        "\n",
        "def search_reports_for_keywords(dataframe, keywords, min_keyword_count=2):\n",
        "    # Initialize an empty list to store matching reports\n",
        "    matching_reports = []\n",
        "\n",
        "    # Iterate through the DataFrame\n",
        "    for index, row in dataframe.iterrows():\n",
        "        report_text = row['report']\n",
        "\n",
        "        # Check if the report contains the word \"void\"\n",
        "        if 'void' in report_text:\n",
        "            # Count how many of the specified keywords are in the report\n",
        "            keyword_count = sum(keyword in report_text for keyword in keywords)\n",
        "\n",
        "            # Check if the count of matching keywords is at least min_keyword_count\n",
        "            if keyword_count >= min_keyword_count:\n",
        "                matching_reports.append((index, report_text))\n",
        "\n",
        "    return matching_reports\n",
        "\n",
        "# List of keywords to search for\n",
        "keywords_to_search = [\"null\", \"empty\", \"missing\", \"error\", \"absence\", \"invalid\", \"blank\", \"unspecified\", \"deleted\", \"unavailable\"]\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "matching_reports = search_reports_for_keywords(df, keywords_to_search, min_keyword_count=2)\n",
        "\n",
        "# Print matching reports\n",
        "for index, report_text in matching_reports:\n",
        "    print(f\"Report Index: {index}, Report Text: {report_text}\\n\")\n",
        "\n",
        "\n",
        "output_filename = 'matching_reports.txt'\n",
        "\n",
        "with open(output_filename, 'w') as output_file:\n",
        "    for index, report_text in matching_reports:\n",
        "        output_file.write(f\"Report Index: {index}, Report Text: {report_text}\\n\")\n",
        "\n",
        "print(f\"Matching reports have been saved to {output_filename}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OqI27McrL6M",
        "outputId": "b4701301-a357-4a88-f147-1a20c71245aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report Index: 21\n",
            "Sentence (Contains 'missing'): My brother stuck his tongue out to reveal the two missing tabs resting on top.\n",
            "\n",
            "Sentence (Contains 'empty'): I found this teddy bear I use to play with that I gave a personality to and made voices for, but it just felt like an empty teddy bear with no presence at all.+5:00 I would say I had passed the hardships of the trip at this point.\n",
            "\n",
            "Report Index: 62\n",
            "Sentence (Contains 'empty'): The substances were ingested only orally, with powders either dissolved in a beverage or swallowed in a gel cap, typically on a well digested or empty stomach.IntroductionHaving experimented with these chemicals relatively extensively, I summarize here my experiences and present some of the conclusions---impressions, perhaps---that have emerged during my protracted period of reflection.For general comparison purposes, typical trip durations were as follows:2C-I:  7-9 hours up; 40-60 minute come-up2C-E:  8-10 hours up; 110-160 minute come-up, 130 minutes average2C-C:  4-6 hours up; 30-60 minute come-up2C-B:  5-7 hours up; 30-60 minute come-upLet us begin with my first mistake.\n",
            "\n",
            "Sentence (Contains 'absence'): With the 2C-E, however, the feeling was not in my head but in the hands, and in the absence of magnets.\n",
            "\n",
            "Sentence (Contains 'absence'): Still there was an absence of body-load, the mellow push of the chloro lessening with the higher doses.\n",
            "\n",
            "Report Index: 110\n",
            "Report Index: 256\n",
            "Sentence (Contains 'empty'): The empty place seemed too large for us, seemed too hard to comprehend.\n",
            "\n",
            "Sentence (Contains 'empty'): Hoisting our bag of tricks high, we left, staring back at the tiny house, wondering what other secrets it held.By this time, in the hot sun, we had finished two bottles of water, having no pockets due to shorts; I tied the empty containers to the corners of a bright green bandanna, letting it hang from a belt loop.\n",
            "\n",
            "Sentence (Contains 'missing'): We evolved, we became stronger, and on that beach, sitting in the shade, staring and trying to comprehend a tugboat moving across the strait, I found what I was looking for, the missing piece to my life.\n",
            "\n",
            "Report Index: 372\n",
            "Sentence (Contains 'empty'): That afternoon at 5:45 PM, (on an otherwise empty stomach) I consumed one of two sacred psychedelic brews, this one containing the organic (and fully safe, legal and non habit forming) psychoactive alkaloids, Myristicin, Safrole, and Elemicin.\n",
            "\n",
            "Sentence (Contains 'void'): At one point I was in a void---outer space, if you will---and I was left in this void to float, as many significant visions were fed unto my being which I cannot explain.During meditation, two images were gazed upon as part of the procedure, one being that of a figure of a naked woman, causing a bold sexual revelation which I must admit did involve sexual gratification but also a more in depth mental revelation about my own sexual history, past and future; and the other being a surreal artistic and psychedelic image called ``3-D vision by Salayuth,'' (provided upon request) which invoked a vision of an Egyptian beetle dancing in a second, less significant ceremony, in which he danced in front of me displaying weapons, and sending different images into my mind.I later experienced the renowned hallucinogenic occurrence of ``seeing sound and hearing sight.'' There were also many vibrant, pleasant and understood-ably fabricated hallucinations---of an energetic ball of electricity pulsating and dancing around in front of me, I attempting to catch and consume it, but being unable to.\n",
            "\n",
            "Sentence (Contains 'void'): Another one was of me being in a void and then taking part in a colossal explosion, a big bang if you will, with ear piercing noise and blinding energy being produced from black nothingness---when somewhere a long the way, I had a powerful realization relating to a point made in a recent essay I wrote entitled ``On Reality.''This was the realization was that what was happening I knew to be hallucinations---Well of course I knew, that there were amazing things happening to me, of course they were hallucinations---but how did I know?\n",
            "\n",
            "Report Index: 504\n",
            "Sentence (Contains 'void'): Anytime I found myself ``thinking'' and falling down an uncomfortable void of anxiety I would (as in meditation) return to the breath -- in and out -- and almost instantly the bliss returned, the cosmic knowledge returned:  ``this is the lesson, this is your being.''  The never ending back and forth from our minds to our body, from our ego to our souls, from our thoughts to our breath, is an endless lesson in forgiveness -- I was learning how to let go and surrender to what is, to the moment, absent of any punishment or perceived outcome.\n",
            "\n",
            "Sentence (Contains 'absence'): He blew something around me and under my shirt and I felt as if gold rain was washing away all my fears, all menacing spirits, and I melted into surrender with bottomless gratitude.The absence of validation and judgment with the embracing of total surrender and forgiveness for the Self and others (many times being the same thing) was a critical lesson.\n",
            "\n",
            "Report Index: 546\n",
            "Sentence (Contains 'void'): Like a coward and a child, I had run back to my parents after my chance at grabbing the world by the tail had dissolved into nonstop intoxication, leaving me destitute, twenty-five pounds underweight, and shell-like in search of my soul.But I didn't encounter these problems immediately upon my return, for I tripped three times during my last week and a half in Virginia (twice on MDA and once on LSD) -- trips I will forever cherish for how they pulled me out of the black webs of depression that had bound my mind and body to the void I had thrown myself in, returning me to the beauty and joy of life that I had been missing for the greater part of a year.\n",
            "\n",
            "Report Index: 665\n",
            "Sentence (Contains 'empty'): In part because I was reminded before I went out not to mix alcohol and K.) It is worth considering that I am a very big guy - weigh about 290, so I find `regular' doses of some things (like x or g) don't always effect me - also I take SSRIs (wellburtin, serzone) regularly, so I have some stuff going on with my serotonin levels before I start.The amount of K I took is hard to determine, but I started the evening with a full bullet bottle (is that a gram?) and (though I shared a reasonable amount) it was almost entirely empty the next day.\n",
            "\n",
            "Sentence (Contains 'missing'): disjointed and not correct, missing data but not completely wrong or inaccurate either.\n",
            "\n",
            "Report Index: 669\n",
            "Report Index: 670\n",
            "Sentence (Contains 'missing'): I think somewhere in all that is where my desire for something profoundly mystical in my life is coming from and why lately I've been missing the mystical experiences that came from psychedelics.I have advanced degrees in a social science and work in an academic setting (I still can't handle a straight job!\n",
            "\n",
            "Sentence (Contains 'absence'): I felt the urge to get up from my chair and move through my immediate environment touching things to make it more real but, oddly, thought of descriptions of the experience I read recently that said people hurt themselves that way in the absence of a sitter.It was as though I was physically being pulled out of consensus reality, where I wanted to stay, and squeezed by a great all-encompassing pressure into another reality, which I wanted to avoid.\n",
            "\n",
            "Report Index: 857\n",
            "Sentence (Contains 'empty'): I quickly went into an empty stall and peed.1:30ish -- after I returned from urinating, I sat back next to C and began to really enjoy my roll.\n",
            "\n",
            "Report Index: 905\n",
            "Sentence (Contains 'void'): Immediately, it was as if the sectional was the only thing in existence, and we were floating all alone in some sort of strange new void or universe on this sectional.\n",
            "\n",
            "Sentence (Contains 'missing'): I'd nudge him to re-orient him, and he'd pick up where he left off without missing a beat like nothing happened!At one point he went to light a cigarette, and I said `Don't light that, man, you're passing out.' And he looked at me and said `You must be hallucinating mutherfucker', and he kept on doing it.\n",
            "\n",
            "Report Index: 1018\n",
            "Sentence (Contains 'void'): We met someintrepid strangers that were baulking at our frontdoor \\& we gave them a thousand blessings for theirvoyage.There was a woman sentinel, or so we thought at theother door, but we passed wihout getting eaten!Once inside, dancing away, jumping about shyly greeting,Spock worked up courage to explore the dining room \\&kitchen space, the dark backyard was too void like.\n",
            "\n",
            "Sentence (Contains 'missing'): What was she missing outon if she left?\n",
            "\n",
            "Report Index: 1032\n",
            "Report Index: 1244\n",
            "Report Index: 1313\n",
            "Sentence (Contains 'empty'): By this point my friend and I were obviously high, and standing still was impossible, the dance floor was empty and I was nowhere near high enough to fly solo on there -- I still kept some inhibitions.\n",
            "\n",
            "Sentence (Contains 'empty'): My brain would then fill in the big empty space, with hexagons or running dotted lines.\n",
            "\n",
            "Sentence (Contains 'blank'): Although, not a clever part to focus on as it rarely happens on the first 125mg hit, so only working at higher levels either means opening a deeper door to perception, or doing much more damage, or both.When combined with cannabis, either before taking MDMA or smoked whilst high, but coming down, these visuals have twice appeared in a different form, in the form of odd runes and symbols -- not from any alphabet I've ever seen (or maybe from reading Stel Pavlou's Decipher ten years ago, that's the closest I can describe it).These symbols were not like the shifting hexagons I saw filling in the detail on blank space, these were like wearing lenses with them printed on, like staring at a blueprint, they were everywhere.\n",
            "\n",
            "Report Index: 1473\n",
            "Sentence (Contains 'void'): I just existed in an empty void of a limbo, sense-less, where I was being pulled away from my body.\n",
            "\n",
            "Report Index: 1644\n",
            "Sentence (Contains 'missing'): I immediately knew that it was the missing link in my hunt for the substance which satisfied me, and then some.Moving on a few months, I had started robbing and burglarizing houses.\n",
            "\n",
            "Report Index: 1670\n",
            "Sentence (Contains 'blank'): I saw other people looking interested in the things people are normally interested in looking at, like magazines and cd's , so I tried to do the same to look a bit normal; but trying to concentrate on anything just made me more inclined to stare at the stupidest things, like blank paper, pencils, etc.We sat on a bench in the middle of the complex where we could just watch evereything happening around us.\n",
            "\n",
            "Report Index: 1687\n",
            "Sentence (Contains 'empty'): I sit back and empty my mind.It's not easy to clear my mind as I've been stuck in a mindloop for what feels like forever.\n",
            "\n",
            "Report Index: 1939\n",
            "Sentence (Contains 'error'): After ten years of trial and error within Australian Shamanic Communities, the procedure has been refined so that the minimal amount of plant material need be consumed for the maximal benefit.The procedure involves adding only the flesh of the cactus with the highest alkaloid content to distilled water, and results in uniform syrup that has potent effects from manageable quantities.\n",
            "\n",
            "Sentence (Contains 'empty'): Watch the pot constantly at this stage.One large stock pot that can hold at least 10 L of distilled water, OR one large pressure cooker (faster procedure)A second large empty container.\n",
            "\n",
            "Sentence (Contains 'empty'): Keep the empty plastic bottles to hold the bulk water extractions prior to the final evaporation.A stainless steel sieve to drain the water from the cactus between repeated water-based extractions.A tea towel to finely filter the solution near the end of the process.A variety of knives to dismember the cactus.Procedure:Preparation of raw ingredients: Harvesting the plantStart with a T.\n",
            "\n",
            "Sentence (Contains 'empty'): Turn off the heat in the morning.Place the sieve above the second large empty container.\n",
            "\n",
            "Sentence (Contains 'empty'): Use the flat end of a serving spoon to gently squeeze excess juice from the chunks in the sieve into the second empty container.The green water now contains the alkaloids from the cactus flesh, and the initial volume of water that was added to the cactus flesh may have reduced in volume by up to 20\\%.\n",
            "\n",
            "Sentence (Contains 'empty'): If you started with 10L of distilled water, there will be approximately 8-9 L of green water strained from the mix.Transfer the green liquid into the 5 L distilled water containers and put aside until ready to begin final evaporation by boiling.Second Water ExtractionRefill the now empty stock pot with another 10 L of distilled water, heat to a boil, and add the now slightly squashed chunks of boiled cactus from the sieve.\n",
            "\n",
            "Sentence (Contains 'empty'): Repeat the sieving process and store extract in the 5 L distilled water bottles until ready to begin final evaporation by boiling.Third Water ExtractionReturn the chunks to the empty stock pot.\n",
            "\n",
            "Sentence (Contains 'empty'): Use a potato masher to crush the chunks until the solids are a mix of glug and some slightly intact pieces of flesh so it looks like a chunky green paste.Again, refill the empty stock pot with another 10 L of distilled water and add the now squashed chunks of boiled cactus from the sieve.\n",
            "\n",
            "Sentence (Contains 'empty'): Repeat this once the third `boil-up' has rested for at least 24 hours.Final Evaporation by BoilingThe empty large stock pot now becomes the final evaporation pot.\n",
            "\n",
            "Report Index: 1990\n",
            "Sentence (Contains 'void'): Some of the strongest peaks of the experience led my mind into a beautiful void that had therapeutic qualities, but no creative problem solving was occurring here.\n",
            "\n",
            "Report Index: 2009\n",
            "Sentence (Contains 'void'): This was a white void with an infinity of swarming black dots, I could hear air raid sirens and the sound of buzzing, In the sea of holes was a giant cross which had a festering bloody pile of guts and organs spread across it staining the wood crimson.\n",
            "\n",
            "Sentence (Contains 'void'): I began to wipe swathes of dots by sweeping glances into the void around me\\ldots`What have you taken ?'I was gaining hope by the minute, stripping the black dots away , removing these taunting false exits\\ldots`What have you taken?\n",
            "\n",
            "Sentence (Contains 'void'): Was it acid ?'Surrounded by a self created white void of comfort I gazed at the final bunch of black dots and knew my release from Hell was merely held by these remaining few \\ldots`He's out of it still.'I had gazed all but two of the black dots away, these two now had a bridge akin to a line seen in a dot to dot puzzle.\n",
            "\n",
            "Sentence (Contains 'void'): The black line bridge had become a visiblechain, the white void had faded to become a hospital room.\n",
            "\n",
            "Sentence (Contains 'missing'): I recalled that I had indeed dropped acid sometime earlier, my Hospital surroundings and the amount of cuts and bruises I had were confirmation to me that whatever I'd done, It had seriously backfired big time!I sat on the edge of the hospital bed, noted a number of missing Items I had recalled having on my person prior to all of this .\n",
            "\n",
            "Report Index: 2095\n",
            "Sentence (Contains 'void'): There was like void in my head.\n",
            "\n",
            "Report Index: 2417\n",
            "Sentence (Contains 'empty'): My preferred way is to insert the syringe into the rectum as shallowly as possible, $\\sim$slowly$\\sim$ push the plunger of the syringe to empty the contents (around 3 seconds), and then I remain standing for around 20 minutes after.\n",
            "\n",
            "Sentence (Contains 'absence'): The absence of comedown effects combined with the euphoria it provides are simply too good to beat!\n",
            "\n",
            "Report Index: 2440\n",
            "Sentence (Contains 'empty'): I had taken it on an empty stomach, and I hadn't hydrated enough.The exact moment I finished puking, I felt amazing.\n",
            "\n",
            "Report Index: 2463\n",
            "Sentence (Contains 'void'): I have turned off all of the lights and am sitting in the glow of my computer screen, there are patterns churning and seeping into the shadowy surfaces cast in blue and teal, quiet and pensive and watching me like timid hagfish scouting out a fresh ocean floor carcass to burrow into.Despite this sense of depth and space and impenetrable void dominating my mind, when I force myself into lucidity it is quite manageable.\n",
            "\n",
            "Sentence (Contains 'empty'): That is the grip of HXE, fearsome like a mighty glacier, fearsome like an shroud of all-consuming fog, fearsome like the span of the night sky over an empty plain, vast terrible and awesome and completely indifferent to human existence like so much else that is vast and terrible and awesome.I am incredibly warm and sweaty.\n",
            "\n",
            "Sentence (Contains 'void'): But there is no world to be had beyond this high-pressure bubble that contains me, there is the infinite recursive void within my skull, where I fall into yet another high pressure bubble bounded by an inconceivable nothingness that extends in directions I cannot perceive.\n",
            "\n",
            "Sentence (Contains 'blank'): My mind feels blank and empty.\n",
            "\n",
            "Sentence (Contains 'empty'): The headspace is empty and confusing, but also accommodating, cozy and warm, to a degree where one doesn't really care about the emptiness.\n",
            "\n",
            "Report Index: 2844\n",
            "Sentence (Contains 'missing'): But I couldn't help but think I had missed something, that a greater treasure still remained to be unlocked.There were a couple more small doses that failed to deliver that missing element, and even a skirmish with bad prints containing a DOx chemical.\n",
            "\n",
            "Report Index: 2889\n",
            "Sentence (Contains 'missing'): This is a safety measure so that the rangers can find you if you've been missing from your car.\n",
            "\n",
            "Report Index: 2918\n",
            "Sentence (Contains 'empty'): L begins to notice the dogs, too, and then, with a sinking feeling, we realize that, a few rows behind us, parked in an empty spot, is a cop car, and another is to our left, in front of the store.\n",
            "\n",
            "Report Index: 2929\n",
            "Sentence (Contains 'empty'): So this is what a simulated reality might consist of from one point of view, albeit a rather abstract one.As this dawned on me I found myself navigating a vast empty office floor in some enormous and distinctly bureaucratic institution.\n",
            "\n",
            "Sentence (Contains 'absence'): I was almost certain in my heart that those issues of right and wrong were real and their absence in the vision I was witnessing was the key to its inauthenticity.As I realised this, the vision snapped away into the gnashing jaws of a somewhat irritated entity focused to the right of my mindspace.\n",
            "\n",
            "Report Index: 2977\n",
            "Sentence (Contains 'empty'): I saw a field of vague patterns, flowing across a great empty void.\n",
            "\n",
            "Sentence (Contains 'empty'): An empty realization.\n",
            "\n",
            "Report Index: 3144\n",
            "Sentence (Contains 'empty'): Maybe shouldn't have taken the extract on empty stomach.\n",
            "\n",
            "Sentence (Contains 'void'): A void of nothing.\n",
            "\n",
            "Report Index: 3273\n",
            "Sentence (Contains 'empty'): I quickly empty it into my belly.\n",
            "\n",
            "Sentence (Contains 'empty'): With all the bottles of wine empty we debate running out to purchase more.\n",
            "\n",
            "Report Index: 3321\n",
            "Report Index: 3473\n",
            "Sentence (Contains 'empty'): I take multiple trips between rooms to get things, only to become indecisive, forget what I was doing, and return back to my room of origin empty handed.I turn to the scale again and weigh 71 mg of methoxetamine.\n",
            "\n",
            "Sentence (Contains 'void'): It is completely free and empty: a pleasant void of sweet nothingness.T + 4:12 [2:17 AM +1]The journey of the night is becoming more intense now.\n",
            "\n",
            "Report Index: 3524\n",
            "Report Index: 3530\n",
            "Sentence (Contains 'error'): I'm still alive, but again, don't be me.Most of the substances were shared by two others, I alone did the 2C-D/2C-M late into the trip to get things going again because one of my friends had issues with their rectal dose of MAL and was on a oral timer, and I didn't want to leave them up alone.This would be a first for any of us on MAL, I'd reagent tested it and done a basic allergy test some weeks ago.The trip was started in the late evening, later than intended but within the expected margin of error [this was not actually a good margin, but oh well] T=00:00 = $\\sim$19:45 for myselfI dosed 36 milligrams of MAL rectally (3ml of a 12mg/ml solution) and had a single tab of what was sold to me as 100ug gel tab LSD, which tested positive for indoles and has repeatedly delivered solid results.\n",
            "\n",
            "Sentence (Contains 'empty'): Intense discomfort and the need to defecate followed about instantly as mentioned above, and I ended up going to the restroom sooner than desired but there was still decent absorption by subjective effects.[00:20 - 01:00]   Writhed around on my bed under a cute blanket while cuddling a plushie with a bucket near by, ended up needing said bucket on a mostly empty stomach and continued to dry heave until the come up settled down.\n",
            "\n",
            "Report Index: 3639\n",
            "Sentence (Contains 'empty'): We were driving out to J's house and we picked up some fast food on the way and ate in an empty parking lot near J's house.\n",
            "\n",
            "Report Index: 3717\n",
            "Sentence (Contains 'absence'): The only significant aspect of it that I can recall is an ample series of gears and machinery in the chaotic background to my reality.The Salvia trip ended as abruptly as it began, and with its absence returned the Psilocybin in full force.\n",
            "\n",
            "Sentence (Contains 'void'): Movement was natural, it seemed, for without knowing I found myself slithering about in this amazing void of random vapors and essences of inhuman color and form.\n",
            "\n",
            "Sentence (Contains 'empty'): These voices, I later discovered, were the voices of my two friends; watching my empty body, unknowing that my mind was elsewhere- trapped within a maze of emptiness and alien abstractness.Finally, this entity that I was discovered a distant hole, shining like a beacon of light in the middle of an unending sea of dark.\n",
            "\n",
            "Report Index: 3781\n",
            "Sentence (Contains 'missing'): My partner and I were in danger of missing our connecting flight, but we decided it would be better if we stuck together.I was pretty freaked out--I carry a small assortment of unlabeled pills and medications wherever I go, some of which are controlled--and after a carefree week of relaxation I was struggling to contain my distaste for the plodding inelegance of `the system'.\n",
            "\n",
            "Sentence (Contains 'empty'): Coca is fine on an empty stomach (it actually helps me when I am hungry and on the trail), and because of its shorter duration, I can use it in the evening and still expect a good night's sleep.\n",
            "\n",
            "Report Index: 3939\n",
            "Sentence (Contains 'empty'): While fully aware that a full come-up could take up to 2 hours, I had taken my dose on an empty stomach and weighing around 55 kg, deduced that the vendor had indeed cited a grossly inaccurate value.\n",
            "\n",
            "Sentence (Contains 'absence'): Abi's absence felt wrong, I spammed her a with a few messages to tell her how much I loved her and how much I needed her right now.I knew I loved this woman before this trip, however I hadn't put much thought into why exactly that was the case.\n",
            "\n",
            "Report Index: 4179\n",
            "Sentence (Contains 'empty'): I had taken it on an empty stomach, and I hadn't hydrated enough.The exact moment I finished puking, I felt amazing.\n",
            "\n",
            "Report Index: 4192\n",
            "Sentence (Contains 'empty'): I measured it out by eye.I had 3 consecutive nights of experiences -Day 1 (roughly 150 mg, 100 mg redose T+3:00) drank with hot coffeeDay 2 (roughly 200 mg, 150 mg redose T+3:00) drank with hot coffeeDrinking the chemical with coffee on an empty stomach made it kick in fast.\n",
            "\n",
            "Report Index: 4328\n",
            "Sentence (Contains 'empty'): I saw the empty Ambien CR bottle in front of me and thought, ``Oh, shit!\n",
            "\n",
            "Sentence (Contains 'empty'): I need a signal to someone.''  So I jammed the empty bottle down on my left index, second finger and thumb until I couldn't shake it off.\n",
            "\n",
            "Report Index: 4427\n",
            "Report Index: 4471\n",
            "Sentence (Contains 'error'): The error in drug name was later corrected in Myron's autobiography, \\emph{Thanatos to Eros}; introducing his subjects to altered states of consciousness by using a mixture of CO2 and oxygen, and by using methadrine (methamphetamine) was the standard approach taken by Al Hubbard.\n",
            "\n",
            "Sentence (Contains 'absence'): Prior to giving them a stronger psychedelic, Hubbard first wanted to make sure that the subject responded well to these milder drugs.] Produced wonderful feeling of [euphoria], heightened intensity of awareness, much greater creativity, complete absence of feelings of anxiety or insecurity.On April 15, the day before the session, spent the entire day talking with my two directors, was tested by each of them with CO2 .\n",
            "\n",
            "Sentence (Contains 'error'): I could see the error of this pattern, and my job was to simply be, be just plain old Myron, even though he were not all the fancy things I had previously thought him to be.\n",
            "\n",
            "Report Index: 4510\n",
            "Sentence (Contains 'absence'): Maybe it was just the changes that occur anywhere in 5 years of absence that made it seem like such an unknown area.\n",
            "\n",
            "Sentence (Contains 'empty'): It was as if my entire field of vision underwent some sort of tectonic upheaval, with one shard jumping violently upward while another sunk sullenly down until it was replaced by an empty black spot.\n",
            "\n",
            "Sentence (Contains 'missing'): Just the sound of her voice made me miss her all that much more, yet at the same time it helped to ease the problem of missing her.\n",
            "\n",
            "Report Index: 4563\n",
            "Sentence (Contains 'empty'): With a stronger solution, like 1 ml it would be easy to empty the syringe as soon as I found a vein.\n",
            "\n",
            "Report Index: 4593\n",
            "Sentence (Contains 'void'): ``Sight, no longer needed!'' exclaimed Cory or Goopstar, and everyone laughed.At some point in time I felt the need to void my bowels.\n",
            "\n",
            "Sentence (Contains 'error'): To explain that better, the concept ``dimensions'' seemed to exist, and not exist, at the same time, and this was no longer a logical error in my mind.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named df\n",
        "\n",
        "# Filter the DataFrame to select only rows with \"void\" in the report\n",
        "void_reports = df[df['report'].str.contains('void', case=False, na=False)]\n",
        "\n",
        "# Select the demographic columns of interest\n",
        "demographic_data = void_reports[['gender', 'drug', 'mixed', 'weight']]\n",
        "\n",
        "# Display the demographic data for reports containing \"void\"\n",
        "print(demographic_data)\n"
      ],
      "metadata": {
        "id": "MT2LA2Vtr3wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to select only rows with \"void\" in the report\n",
        "void_reports = df[df['report'].str.contains('void', case=False, na=False)]\n",
        "\n",
        "# Calculate the total count of males and females\n",
        "gender_counts = void_reports['gender'].value_counts()\n",
        "\n",
        "# Calculate the average weight\n",
        "average_weight = void_reports['weight'].mean()\n",
        "\n",
        "# Calculate the drug types that produced the word \"void\" more frequently\n",
        "drug_counts = void_reports['drug'].value_counts()\n",
        "\n",
        "# Calculate the count of reports that are mixed and not mixed\n",
        "mixed_counts = void_reports['mixed'].value_counts()\n",
        "\n",
        "# Display the results\n",
        "print(f\"Total Count of Males: {gender_counts.get('male', 0)}\")\n",
        "print(f\"Total Count of Females: {gender_counts.get('female', 0)}\")\n",
        "print(f\"Average Weight: {average_weight:.2f} grams\")\n",
        "print(\"Drug Types Producing 'Void' More Frequently:\")\n",
        "print(drug_counts)\n",
        "print(f\"Count of Mixed Reports: {mixed_counts.get(1, 0)}\")\n",
        "print(f\"Count of Not Mixed Reports: {mixed_counts.get(0, 0)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUTKDSbfuWui",
        "outputId": "aad6803a-dad9-4fad-885b-5aeae09b2e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Count of Males: 6326\n",
            "Total Count of Females: 895\n",
            "Average Weight: 161.97 grams\n",
            "Drug Types Producing 'Void' More Frequently:\n",
            "cannabis                644\n",
            "lsd                     554\n",
            "salvia divinorum        482\n",
            "mushrooms               408\n",
            "mdma                    388\n",
            "                       ... \n",
            "vitamin b-6               1\n",
            "methcathinone             1\n",
            "eth-lad                   1\n",
            "pharms - propranolol      1\n",
            "turbina corymbosa         1\n",
            "Name: drug, Length: 416, dtype: int64\n",
            "Count of Mixed Reports: 4651\n",
            "Count of Not Mixed Reports: 2984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpyU7DF2usTX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}